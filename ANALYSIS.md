# プロジェクトの全体的な問題点と改善案の分析

このドキュメントは、プロジェクトのコードベースとドキュメントをレビューし、特定された全体的な問題点と改善の可能性についてまとめたものです。ユーザーの要求に基づき、この分析をGitHub上で保存するために作成されました。

---

### 分析サマリ

このプロジェクトは、ローカル環境で動作する日本語HTML向けの関連ページ推定システムとして、よく設計されています。特に、文字n-gramによるTF-IDFと、日本語に特化した埋め込みモデルによる再ランキングを組み合わせるアプローチは堅実です。

その上で、プロジェクト全体として改善の可能性がある点を8つ挙げます。

---

### プロジェクトの全体的な問題点と改善案

1.  **コードの重複とモジュール性の欠如**
    *   **問題点:** `build_index.py`と`score_related.py`の間で、テキストの正規化 (`normalize_text`)、HTMLからのテキスト抽出 (`extract_text_from_html`)、チャンク分割 (`_chunk_text`) といった複数の関数が重複して実装されています。これは、将来の機能修正や拡張の際に、両方のファイルを修正する必要があり、メンテナンス性を低下させる原因となります。
    *   **改善案:** これらの共通機能を `core.py` や `utils.py` のような共有モジュールに切り出し、両方のスクriptからインポートして利用する構成にリファクタリングすることが推奨されます。

2.  **複雑な手動セットアップ**
    *   **問題点:** 利用開始までに、複数の`pip`コマンドの実行や、Hugging Faceからのモデルの手動ダウンロード・配置が必要です。これは特に技術的な知識が少ない利用者にとってはハードルが高く、エラーの原因となり得ます。
    *   **改善案:** `requirements.txt`ファイルを提供して依存関係を一度にインストールできるようにしたり、モデルのダウンロードと配置を自動化するセットアップスクリプト（`setup.py`やシェルスクリプト）を用意したりすることで、導入が容易になります。

3.  **プラットフォーム固有のツール**
    *   **問題点:** `build_index.bat`や`score_related.bat`といったバッチファイルが提供されていますが、これらはWindows環境でしか動作しません。macOSやLinuxの利用者は、`README.md`を読んで手動でコマンドを組み立てる必要があります。
    *   **改善案:** 同等の機能を持つシェルスクリプト（`.sh`ファイル）を提供することで、クロスプラットフォーム対応が向上します。

4.  **スケーラビリティの制限**
    *   **問題点:** `TECHNICAL_DETAILS.md`にも記載がある通り、現在の類似度計算は全候補に対する総当たり、またはTF-IDFで絞った上位候補に対する線形スキャンです。HTMLファイルの数が数万〜数十万と大規模になった場合、特に埋め込みを用いた検索のパフォーマンスが課題となる可能性があります。
    *   **改善案:** `Faiss`や`HNSWlib`のようなライブラリを用いて、埋め込みベクトルに対するANN（近似最近傍探索）インデックスを構築することで、検索を大幅に高速化できます。

5.  **単純なHTMLからのテキスト抽出**
    *   **問題点:** 現在の実装では、特定のCSSセレクタ（`nav`, `footer`など）を指定して不要な部分を除外していますが、現代のウェブページは広告、クッキーバナー、関連記事リンクなど、より複雑な「ボイラープレート（定型文）」を含みます。これらがノイズとしてテキストに含まれると、検索精度に影響を与える可能性があります。
    *   **改善案:** `trafilatura`や`jusText`といったボイラープレート除去に特化したライブラリを導入し、HTMLから本文のみをより高精度に抽出することを検討する価値があります。

6.  **煩雑なパラメータ管理**
    *   **問題点:** 両スクリプトとも、多数のコマンドライン引数（TF-IDFのパラメータ、重み、チャンク設定、リランク設定など）を受け取ります。これによりコマンドが長くなりがちで、実験設定の再現や管理が難しくなっています。
    *   **改善案:** `config.yaml`や`settings.json`のような設定ファイルを導入し、各種パラメータをファイルで管理できるようにすると、見通しが良くなり、実験の再現性も高まります。

7.  **評価フレームワークの不在**
    *   **問題点:** 「良い関連ページ」が何かを定量的に評価する仕組みがありません。そのため、各種パラメータ（`alpha`の重み、`ngram`のサイズなど）や、異なる埋め込みモデルの性能を客観的に比較することが困難です。
    *   **改善案:** クエリと正解の関連ページリストからなる評価データセットを用意し、それを使ってNDCGやMAP (Mean Average Precision) といった検索評価指標を計算する簡単な評価スクリプトを追加すると、チューニングが格段に行いやすくなります。

8.  **モデル選択の柔軟性**
    *   **問題点:** ドキュメントや設計が`sonoisa/sentence-bert-base-ja-mean-tokens-v2`という単一のモデルを強く推奨しており、他のモデルを試す際の手間が大きくなっています。
    *   **改善案:** より汎用的なモデル読み込み処理にしたり、Hugging Faceで人気の他の日本語モデル（E5系など）を試すためのガイドや設定例を追記したりすることで、利用者が自身のデータセットに最適なモデルを見つけやすくなります。
